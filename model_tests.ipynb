{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from fastai.vision.all import *\n",
    "import cv2\n",
    "\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "from utils import IMG_SIZE_X, IMG_SIZE_Y, preprocess_img, get_learner\n",
    "from window_capture import WindowCapture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\learner.py:58: UserWarning: Saved filed doesn't contain an optimizer state.\n",
      "  elif with_opt: warn(\"Saved filed doesn't contain an optimizer state.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-17.513179779052734,\n",
       " 0.18108314275741577,\n",
       " 25.859399795532227,\n",
       " -4.372618675231934,\n",
       " -4.293115615844727,\n",
       " -17.583904266357422,\n",
       " 34.15899658203125,\n",
       " -5.687933921813965,\n",
       " -11.480090141296387,\n",
       " -0.9243593215942383)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = get_learner('models/tiny384_2heads_160k_03off')\n",
    "\n",
    "\n",
    "wincap = WindowCapture('Need for Speed™ Most Wanted')\n",
    "screen = wincap.get_screenshot()\n",
    "\n",
    "img = preprocess_img(screen)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = np.moveaxis(img, -1, 0)\n",
    "learn.predict((img, torch.tensor(32.3)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvnextWithSpeed(nn.Module):\n",
    "    def __init__(self, model): \n",
    "        super().__init__()\n",
    "        head_layers = list(model[-1].children())\n",
    "        head_layers[4] = torch.nn.Linear(in_features=1537, out_features=512, bias=False)\n",
    "        self.img_body = nn.Sequential(model[:-1], nn.Sequential(*head_layers[:4]))\n",
    "        self.head = nn.Sequential(*head_layers[4:])\n",
    "\n",
    "    def forward(self, *x):\n",
    "        img, speed = x\n",
    "        x_img = self.img_body(img)\n",
    "        x = torch.cat([x_img, speed[:, None]], dim=1)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dls_from_np(images, speeds, labels, num_train):\n",
    "    num_images = images.shape[0]\n",
    "    \n",
    "    def pass_index(idx):\n",
    "        return idx\n",
    "\n",
    "    def get_x(i):\n",
    "        return images[i], speeds[i]\n",
    "\n",
    "    def get_y(i):\n",
    "        # FOR MINIMAP ROTATION REGRESSION\n",
    "        return labels[i]\n",
    "        \n",
    "        # FOR MINIMAP ROTATION CLASSIFICATION\n",
    "        # return 0 if np.abs(labels[i]) <= 1 else np.sign(labels[i])\n",
    "        \n",
    "        # FOR KB INPUT CLASSIFICATION \n",
    "        # return CONVERT_INPUT.index(labels[i][2:])\n",
    "\n",
    "    dblock = DataBlock(\n",
    "        blocks=(ImageBlock, RegressionBlock),\n",
    "        # blocks=(ImageBlock, CategoryBlock),\n",
    "        get_items=pass_index,\n",
    "        get_x=get_x,\n",
    "        get_y=get_y,\n",
    "        # item_tfms=[Resize((224, 224), method='squish')],\n",
    "        splitter=IndexSplitter(list(range(num_train, num_images)))\n",
    "        # splitter=EndSplitter(valid_pct=0.1)\n",
    "        )\n",
    "    # pass in a list of index\n",
    "    dls = dblock.dataloaders(list(range(num_images)), shuffle=True, bs=64)\n",
    "\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-0.04791807383298874,\n",
       " 1.0886561870574951,\n",
       " 12.747199058532715,\n",
       " -3.7238669395446777,\n",
       " -3.34065318107605,\n",
       " -2.268181562423706,\n",
       " 13.475717544555664,\n",
       " -5.935239791870117,\n",
       " -2.7679271697998047,\n",
       " 0.38461923599243164)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def speed_loss(pred, speed, angle, ws, ad): return F.mse_loss(pred[:, 0], speed)\n",
    "def angle_loss(pred, speed, angle, ws, ad): return F.mse_loss(pred[:, 1], angle)\n",
    "def kb_input_loss(pred, speed, angle, ws, ad):\n",
    "    return F.cross_entropy(pred[:, 2:6], ws, ignore_index=-2) + F.cross_entropy(pred[:, 6:], ad, ignore_index=-2)\n",
    "    \n",
    "def combine_loss(pred, speed, angle, ws, ad, reduction='none'): return speed_loss(pred, speed, angle, ws, ad) \\\n",
    "                                                                       + angle_loss(pred, speed, angle, ws, ad) \\\n",
    "                                                                       + kb_input_loss(pred, speed, angle, ws, ad)\n",
    "\n",
    "dummy_x = np.empty(shape=(1, IMG_SIZE_Y, IMG_SIZE_X, 3), dtype=np.uint8)\n",
    "dummy_speed = np.empty(shape=(1, ), dtype=np.uint8)\n",
    "dummy_y = np.empty(shape=(1, ))\n",
    "dls = dls_from_np(dummy_x, dummy_speed, dummy_y, num_train=1)\n",
    "\n",
    "class ConvnextWithSpeed(nn.Module):\n",
    "    def __init__(self, model): \n",
    "        super().__init__()\n",
    "        head_layers = list(model[-1].children())\n",
    "        head_layers[4] = torch.nn.Linear(in_features=1537, out_features=512, bias=False)\n",
    "        self.img_body = nn.Sequential(model[:-1], nn.Sequential(*head_layers[:4]))\n",
    "        self.head = nn.Sequential(*head_layers[4:])\n",
    "\n",
    "    def forward(self, x):\n",
    "        img, speed = x\n",
    "        x_img = self.img_body(img/255)\n",
    "        x = torch.cat([x_img, speed[:, None]], dim=1)\n",
    "        return self.head(x)\n",
    "    \n",
    "# create model\n",
    "model = ConvnextWithSpeed(create_timm_model('convnext_tiny_384_in22ft1k', n_out=10)[0])\n",
    "learn = Learner(dls, model, loss_func=combine_loss, metrics=(speed_loss, angle_loss, kb_input_loss), cbs=GradientAccumulation(64))\n",
    "# freeze the model\n",
    "learn.model.img_body[0].requires_grad_(False)\n",
    "for module in learn.model.img_body[0].modules():\n",
    "    if isinstance(module, nn.LayerNorm):\n",
    "        if hasattr(module, 'weight'):\n",
    "            module.weight.requires_grad_(True)\n",
    "        if hasattr(module, 'bias'):\n",
    "            module.bias.requires_grad_(True)\n",
    "        module.eval()\n",
    "        \n",
    "learn.load('tiny384_70k_allinp_v1')\n",
    "\n",
    "\n",
    "wincap = WindowCapture('Need for Speed™ Most Wanted')\n",
    "screen = wincap.get_screenshot()\n",
    "\n",
    "img = preprocess_img(screen)\n",
    "img = np.moveaxis(img, -1, 0)\n",
    "learn.predict((img, 12))[0]\n",
    "# # dl = dls.test_dl(img, torch.tensor(12))\n",
    "# dl = dls.test_dl([(img, 12)])\n",
    "# preds=learn.get_preds(dl=dl)\n",
    "# preds[0]\n",
    "\n",
    "# learn.summary()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\learner.py:58: UserWarning: Saved filed doesn't contain an optimizer state.\n",
      "  elif with_opt: warn(\"Saved filed doesn't contain an optimizer state.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Match length mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [128], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m img \u001b[39m=\u001b[39m preprocess_img(screen)\n\u001b[0;32m     55\u001b[0m \u001b[39m# img = np.moveaxis(img, -1, 0)\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m learn\u001b[39m.\u001b[39mpredict([img, \u001b[39m12\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mg:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\learner.py:306\u001b[0m, in \u001b[0;36mLearner.predict\u001b[1;34m(self, item, rm_type_tfms, with_input)\u001b[0m\n\u001b[0;32m    304\u001b[0m i \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls, \u001b[39m'\u001b[39m\u001b[39mn_inp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    305\u001b[0m inp \u001b[39m=\u001b[39m (inp,) \u001b[39mif\u001b[39;00m i\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m tuplify(inp)\n\u001b[1;32m--> 306\u001b[0m dec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdls\u001b[39m.\u001b[39;49mdecode_batch(inp \u001b[39m+\u001b[39;49m tuplify(dec_preds))[\u001b[39m0\u001b[39m]\n\u001b[0;32m    307\u001b[0m dec_inp,dec_targ \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(detuplify, [dec[:i],dec[i:]])\n\u001b[0;32m    308\u001b[0m res \u001b[39m=\u001b[39m dec_targ,dec_preds[\u001b[39m0\u001b[39m],preds[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mg:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\data\\core.py:121\u001b[0m, in \u001b[0;36mTfmdDL.decode_batch\u001b[1;34m(self, b, max_n, full)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode_batch\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[0;32m    117\u001b[0m     b, \u001b[39m# Batch to decode\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     max_n:\u001b[39mint\u001b[39m\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m, \u001b[39m# Maximum number of items to decode\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     full:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m \u001b[39m# Whether to decode all transforms. If `False`, decode up to the point the item knows how to show itself\u001b[39;00m\n\u001b[0;32m    120\u001b[0m ): \n\u001b[1;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decode_batch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecode(b), max_n, full)\n",
      "File \u001b[1;32mg:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\data\\core.py:127\u001b[0m, in \u001b[0;36mTfmdDL._decode_batch\u001b[1;34m(self, b, max_n, full)\u001b[0m\n\u001b[0;32m    125\u001b[0m f1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbefore_batch\u001b[39m.\u001b[39mdecode\n\u001b[0;32m    126\u001b[0m f \u001b[39m=\u001b[39m compose(f1, f, partial(getcallable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset,\u001b[39m'\u001b[39m\u001b[39mdecode\u001b[39m\u001b[39m'\u001b[39m), full \u001b[39m=\u001b[39m full))\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m L(batch_to_samples(b, max_n\u001b[39m=\u001b[39;49mmax_n))\u001b[39m.\u001b[39;49mmap(f)\n",
      "File \u001b[1;32mg:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastcore\\foundation.py:156\u001b[0m, in \u001b[0;36mL.map\u001b[1;34m(self, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m--> 156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, f, \u001b[39m*\u001b[39margs, gen\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(map_ex(\u001b[39mself\u001b[39m, f, \u001b[39m*\u001b[39margs, gen\u001b[39m=\u001b[39mgen, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mg:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastcore\\basics.py:840\u001b[0m, in \u001b[0;36mmap_ex\u001b[1;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(g, iterable)\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m gen: \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m--> 840\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(res)\n",
      "File \u001b[1;32mg:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastcore\\basics.py:825\u001b[0m, in \u001b[0;36mbind.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v,_Arg): kwargs[k] \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mpop(v\u001b[39m.\u001b[39mi)\n\u001b[0;32m    824\u001b[0m fargs \u001b[39m=\u001b[39m [args[x\u001b[39m.\u001b[39mi] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, _Arg) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpargs] \u001b[39m+\u001b[39m args[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 825\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39mfargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mg:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastcore\\basics.py:850\u001b[0m, in \u001b[0;36mcompose.<locals>._inner\u001b[1;34m(x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_inner\u001b[39m(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 850\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m funcs: x \u001b[39m=\u001b[39m f(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    851\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mg:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastai\\data\\core.py:463\u001b[0m, in \u001b[0;36mDatasets.decode\u001b[1;34m(self, o, full)\u001b[0m\n\u001b[1;32m--> 463\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, o, full\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m): \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(tl\u001b[39m.\u001b[39mdecode(o_, full\u001b[39m=\u001b[39mfull) \u001b[39mfor\u001b[39;00m o_,tl \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(o,tuplify(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtls, match\u001b[39m=\u001b[39;49mo)))\n",
      "File \u001b[1;32mg:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastcore\\basics.py:77\u001b[0m, in \u001b[0;36mtuplify\u001b[1;34m(o, use_list, match)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtuplify\u001b[39m(o, use_list\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, match\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     76\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mMake `o` a tuple\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(listify(o, use_list\u001b[39m=\u001b[39;49muse_list, match\u001b[39m=\u001b[39;49mmatch))\n",
      "File \u001b[1;32mg:\\anaconda3\\envs\\ml\\lib\\site-packages\\fastcore\\basics.py:71\u001b[0m, in \u001b[0;36mlistify\u001b[1;34m(o, use_list, match, *rest)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m is_coll(match): match \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(match)\n\u001b[0;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(res)\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m: res \u001b[39m=\u001b[39m res\u001b[39m*\u001b[39mmatch\n\u001b[1;32m---> 71\u001b[0m     \u001b[39melse\u001b[39;00m: \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(res)\u001b[39m==\u001b[39mmatch, \u001b[39m'\u001b[39m\u001b[39mMatch length mismatch\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     72\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "\u001b[1;31mAssertionError\u001b[0m: Match length mismatch"
     ]
    }
   ],
   "source": [
    "dummy_x = np.empty(shape=(IMG_SIZE_Y, IMG_SIZE_X, 3), dtype=np.uint8)\n",
    "dummy_speed = np.empty(shape=(1, ), dtype=np.uint16)\n",
    "\n",
    "def get_x(x):\n",
    "    return x\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, RegressionBlock, RegressionBlock, RegressionBlock, CategoryBlock([-2, -1, 0, 1]), CategoryBlock([-2, -1, 0, 1])),\n",
    "    # get_items=lambda x: x,\n",
    "    # get_x=[lambda x: x[0]] * 2,\n",
    "    get_x=[ItemGetter(i) for i in range(2)],\n",
    "    get_y=[ItemGetter(i) for i in range(2, 6)],\n",
    "    # get_x=[get_x, get_x],\n",
    "    # get_y=4*[lambda x: 1],\n",
    "    # get_y=[ColReader('speed_diff'), ColReader('angle_diff'), ColReader('ws'), ColReader('ad')],\n",
    "    n_inp=2\n",
    "    )\n",
    "dls = dblock.dataloaders([[dummy_x, dummy_speed, 1, 1, 1, 1]])\n",
    "\n",
    "class ConvnextWithSpeed(nn.Module):\n",
    "    def __init__(self, model): \n",
    "        super().__init__()\n",
    "        head_layers = list(model[-1].children())\n",
    "        head_layers[4] = torch.nn.Linear(in_features=1537, out_features=512, bias=False)\n",
    "        self.img_body = nn.Sequential(model[:-1], nn.Sequential(*head_layers[:4]))\n",
    "        self.head = nn.Sequential(*head_layers[4:])\n",
    "\n",
    "    def forward(self, *x):\n",
    "        img, speed = x\n",
    "        x_img = self.img_body(img/255)\n",
    "        x = torch.cat([x_img, speed[:, None]], dim=1)\n",
    "        return self.head(x)\n",
    "    \n",
    "# create model\n",
    "model = ConvnextWithSpeed(create_timm_model('convnext_tiny_384_in22ft1k', n_out=10)[0])\n",
    "learn = Learner(dls, model, loss_func=combine_loss, metrics=(speed_loss, angle_loss, kb_input_loss), cbs=GradientAccumulation(64))\n",
    "# freeze the model\n",
    "learn.model.img_body[0].requires_grad_(False)\n",
    "for module in learn.model.img_body[0].modules():\n",
    "    if isinstance(module, nn.LayerNorm):\n",
    "        if hasattr(module, 'weight'):\n",
    "            module.weight.requires_grad_(True)\n",
    "        if hasattr(module, 'bias'):\n",
    "            module.bias.requires_grad_(True)\n",
    "        module.eval()\n",
    "        \n",
    "learn.load('tiny384_70k_allinp_v1')\n",
    "\n",
    "\n",
    "wincap = WindowCapture('Need for Speed™ Most Wanted')\n",
    "screen = wincap.get_screenshot()\n",
    "\n",
    "img = preprocess_img(screen)\n",
    "# img = np.moveaxis(img, -1, 0)\n",
    "learn.predict([img, 12, 0, 0, 0, 0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AdaptiveConcatPool2d(\n",
       "   (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "   (mp): AdaptiveMaxPool2d(output_size=1)\n",
       " ),\n",
       " fastai.layers.Flatten(full=False),\n",
       " BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Dropout(p=0.25, inplace=False),\n",
       " Linear(in_features=1537, out_features=512, bias=False),\n",
       " ReLU(inplace=True),\n",
       " BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Dropout(p=0.5, inplace=False),\n",
       " Linear(in_features=512, out_features=2, bias=False)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_layers = list(learn.model[-1].children())\n",
    "nn.Sequential(*head_layers[:3])\n",
    "# # head_layers.insert(3, torch.cat([img, ], dim=1))\n",
    "head_layers[4] = torch.nn.Linear(in_features=1537, out_features=512, bias=False)\n",
    "head_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(learn.model[-1].children())[2]\n",
    "# learn.model[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed = list(learn.model[-1].children())[:-1]\n",
    "# model= torch.nn.Sequential(*removed)\n",
    "# learn.model[-1] = model\n",
    "# learn.model[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "575b27b03c8f4938561cc9027b66655be84e7082a51e87d8eb0fbf4ab5514768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
